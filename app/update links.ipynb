{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "thrown-asbestos",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import requests\n",
    "import re\n",
    "import lxml.etree as etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tight-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "criminal-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "diagnostic-manor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryByIndex:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        q = requests.get(url)\n",
    "        c = lxml.html.fromstring(q.text)\n",
    "        self.matches = c.xpath(\"//li/span[@class='b-doc-expl']/parent::*\")\n",
    "        self.starts_from = int(c.xpath(\"//ol[@start]\")[0].get('start'))\n",
    "    \n",
    "    def get_match_by_position(self, position):\n",
    "        return self.matches[position - self.starts_from]\n",
    "    \n",
    "    def get_link_from_match(self, match, items):\n",
    "        exp_links = match.xpath(\".//a[contains(., '←…→')]\")\n",
    "        final_url = None\n",
    "        nk_prefix = 'https://processing.ruscorpora.ru/'\n",
    "        end_clear = re.compile(r'\\s+\\[[^\\]]+\\]\\s+\\[[^\\]]+\\]\\s+←…→$')\n",
    "        item_text = \"\".join([i[\"text\"] for i in items])\n",
    "        item_text = re.sub(r'\\s+', ' ', item_text)\n",
    "        if len(exp_links) == 1:\n",
    "            final_url = nk_prefix + exp_links[0].get('href')\n",
    "        else:\n",
    "            hamming = []\n",
    "            for n, link in enumerate(exp_links):\n",
    "                li_text = link.xpath('string(./..)')\n",
    "                li_text = re.sub(end_clear, \"\", li_text)\n",
    "                li_text = re.sub(r'\\s+', ' ', li_text)\n",
    "                hamming.append([n, similar(li_text, item_text)])\n",
    "\n",
    "            i = sorted(hamming, key=lambda x: x[1])[-1][0]\n",
    "            final_url = nk_prefix + exp_links[i].get('href')\n",
    "        return final_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "about-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_on_file(dataset_name):\n",
    "    j = json.loads(\n",
    "            open(os.path.join(\"..\", \"files\", \"datasets\", dataset_name), encoding=\"utf-8\").read())\n",
    "    has_expanded = False\n",
    "    index_urls = {}\n",
    "    for n, item in enumerate(j[\"nk:datasetContent\"][\"items\"]):\n",
    "        if \"itemExpandURL\" in item:\n",
    "            has_expanded = True\n",
    "            break\n",
    "        \n",
    "        url = item[\"itemURL\"]\n",
    "        page = int(item[\"itemPageIndex\"])\n",
    "        position = int(item[\"indexInPage\"])\n",
    "        if page not in index_urls:\n",
    "            index_urls[page] = QueryByIndex(url)\n",
    "        \n",
    "        a = index_urls[page]\n",
    "        l = a.get_link_from_match(a.get_match_by_position(position), item[\"text\"])\n",
    "        \n",
    "        item[\"itemExpandURL\"] = l\n",
    "        \n",
    "        j[\"nk:datasetContent\"][\"items\"][n] = item\n",
    "    \n",
    "    if has_expanded:\n",
    "        print(f\"Skipping {dataset_name}\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(\"..\", \"files\", \"datasets\", dataset_name), \"w\", encoding=\"utf-8\") as json_writer:\n",
    "        json_writer.write(json.dumps(j))\n",
    "        json_writer.close()\n",
    "        \n",
    "    print(f\"Updated file {dataset_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governmental-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "indoor-klein",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20/120) НКРЯ_за_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_за_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(21/120) НКРЯ_за_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_за_ВАР_ОтрМестИнтерпозиция.json\n",
      "(22/120) НКРЯ_за_ВАР_Удвоение.json\n",
      "x\n",
      "x\n",
      "x\n",
      "x\n",
      "x\n",
      "(23/120) НКРЯ_из-за_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_из-за_ВАР_АмальгамыИнтерпозиция.json\n",
      "(24/120) НКРЯ_из-за_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_из-за_ВАР_АппроксИнверсия.json\n",
      "(25/120) НКРЯ_из-за_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_из-за_ВАР_ОтрМестИнтерпозиция.json\n",
      "(26/120) НКРЯ_из-за_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_из-за_ВАР_Удвоение.json\n",
      "(27/120) НКРЯ_из_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_из_ВАР_АппроксИнверсия.json\n",
      "(28/120) НКРЯ_из_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_из_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(29/120) НКРЯ_из_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_из_ВАР_ОтрМестИнтерпозиция.json\n",
      "(30/120) НКРЯ_из_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_из_ВАР_Удвоение.json\n",
      "(31/120) НКРЯ_к_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_к_ВАР_АппроксИнверсия.json\n",
      "(32/120) НКРЯ_к_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_к_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(33/120) НКРЯ_к_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_к_ВАР_Удвоение.json\n",
      "(34/120) НКРЯ_на_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_на_ВАР_АппроксИнверсия.json\n",
      "(35/120) НКРЯ_на_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_на_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(36/120) НКРЯ_на_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_на_ВАР_Удвоение.json\n",
      "(37/120) НКРЯ_над_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_над_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(38/120) НКРЯ_над_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_над_ВАР_ОтрМестИнтерпозиция.json\n",
      "(39/120) НКРЯ_над_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_над_ВАР_Удвоение.json\n",
      "(40/120) НКРЯ_о_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_о_ВАР_АппроксИнверсия.json\n",
      "(41/120) НКРЯ_о_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_о_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(42/120) НКРЯ_о_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_о_ВАР_ОтрМестИнтерпозиция.json\n",
      "(43/120) НКРЯ_о_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_о_ВАР_Удвоение.json\n",
      "(44/120) НКРЯ_от_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_от_ВАР_АппроксИнверсия.json\n",
      "(45/120) НКРЯ_от_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_от_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(46/120) НКРЯ_от_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_от_ВАР_ОтрМестИнтерпозиция.json\n",
      "(47/120) НКРЯ_от_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_от_ВАР_Удвоение.json\n",
      "(48/120) НКРЯ_перед_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_перед_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(49/120) НКРЯ_перед_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_перед_ВАР_ОтрМестИнтерпозиция.json\n",
      "(50/120) НКРЯ_перед_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_перед_ВАР_Удвоение.json\n",
      "(51/120) НКРЯ_по_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_по_ВАР_АппроксИнверсия.json\n",
      "(52/120) НКРЯ_по_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_по_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(53/120) НКРЯ_по_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_по_ВАР_ОтрМестИнтерпозиция.json\n",
      "(54/120) НКРЯ_по_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_по_ВАР_Удвоение.json\n",
      "(55/120) НКРЯ_под_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_под_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(56/120) НКРЯ_под_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_под_ВАР_ОтрМестИнтерпозиция.json\n",
      "(57/120) НКРЯ_под_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_под_ВАР_Удвоение.json\n",
      "(58/120) НКРЯ_при_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_при_ВАР_АппроксИнверсия.json\n",
      "(59/120) НКРЯ_при_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_при_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(60/120) НКРЯ_при_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_при_ВАР_ОтрМестИнтерпозиция.json\n",
      "(61/120) НКРЯ_при_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_при_ВАР_Удвоение.json\n",
      "(62/120) НКРЯ_про_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_про_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(63/120) НКРЯ_про_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_про_ВАР_ОтрМестИнтерпозиция.json\n",
      "(64/120) НКРЯ_про_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_про_ВАР_Удвоение.json\n",
      "(65/120) НКРЯ_с_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_с_ВАР_АппроксИнверсия.json\n",
      "(66/120) НКРЯ_с_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_с_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(67/120) НКРЯ_с_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_с_ВАР_ОтрМестИнтерпозиция.json\n",
      "(68/120) НКРЯ_с_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_с_ВАР_Удвоение.json\n",
      "(69/120) НКРЯ_у_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_у_ВАР_АппроксИнверсия.json\n",
      "(70/120) НКРЯ_у_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_у_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(71/120) НКРЯ_у_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_у_ВАР_ОтрМестИнтерпозиция.json\n",
      "(72/120) НКРЯ_у_ВАР_Удвоение.json\n",
      "Skipping НКРЯ_у_ВАР_Удвоение.json\n",
      "(73/120) НКРЯ_через_ВАР_АппроксИнверсия.json\n",
      "Skipping НКРЯ_через_ВАР_АппроксИнверсия.json\n",
      "(74/120) НКРЯ_через_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "Skipping НКРЯ_через_ВАР_ДвРефлексивИнтерпозиция.json\n",
      "(75/120) НКРЯ_через_ВАР_ОтрМестИнтерпозиция.json\n",
      "Skipping НКРЯ_через_ВАР_ОтрМестИнтерпозиция.json\n",
      "(76/120) НКРЯ_из_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_из_ВАР_АмальгамыИнтерпозиция.json\n",
      "(77/120) НКРЯ_к_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_к_ВАР_АмальгамыИнтерпозиция.json\n",
      "(78/120) НКРЯ_на_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_на_ВАР_АмальгамыИнтерпозиция.json\n",
      "(79/120) НКРЯ_над_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_над_ВАР_АмальгамыИнтерпозиция.json\n",
      "(80/120) НКРЯ_о_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_о_ВАР_АмальгамыИнтерпозиция.json\n",
      "(81/120) НКРЯ_от_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_от_ВАР_АмальгамыИнтерпозиция.json\n",
      "(82/120) НКРЯ_перед_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_перед_ВАР_АмальгамыИнтерпозиция.json\n",
      "(83/120) НКРЯ_по_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_по_ВАР_АмальгамыИнтерпозиция.json\n",
      "(84/120) НКРЯ_под_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_под_ВАР_АмальгамыИнтерпозиция.json\n",
      "(85/120) НКРЯ_при_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_при_ВАР_АмальгамыИнтерпозиция.json\n",
      "(86/120) НКРЯ_про_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_про_ВАР_АмальгамыИнтерпозиция.json\n",
      "(87/120) НКРЯ_с_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_с_ВАР_АмальгамыИнтерпозиция.json\n",
      "(88/120) НКРЯ_у_ВАР_АмальгамыИнтерпозиция.json\n",
      "Skipping НКРЯ_у_ВАР_АмальгамыИнтерпозиция.json\n"
     ]
    }
   ],
   "source": [
    "start_from = 20\n",
    "for n, dataset_name in enumerate(os.listdir(os.path.join(\"..\", \"files\", \"datasets\"))):\n",
    "    if n < start_from:\n",
    "        continue\n",
    "    print(f\"({n}/120) {dataset_name}\")\n",
    "    for x in range(5):\n",
    "        try:\n",
    "            update_on_file(dataset_name)\n",
    "            break\n",
    "        except IndexError:\n",
    "            print(\"x\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-guess",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
